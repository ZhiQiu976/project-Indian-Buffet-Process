{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading required packages\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import uniform as unif\n",
    "from scipy.stats import multivariate_normal as mvtnorm\n",
    "from scipy.stats import bernoulli\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indian Buffet Process Function\n",
    "\n",
    "def sampleIBP(alpha, num_objects):  \n",
    "    # Initializing storage for results\n",
    "    result = np.zeros([num_objects, 1000])\n",
    "    # Draw from the prior for alpha\n",
    "    t = np.random.poisson(alpha)\n",
    "    # Filling in first row of result matrix\n",
    "    result[0, 0:t] = np.ones(t) #changed form np.ones([1, t])\n",
    "    # Initializing K+\n",
    "    K_plus = t\n",
    "    \n",
    "    for i in range(1, num_objects):\n",
    "        for j in range(0, K_plus):\n",
    "            p = np.array([np.log(np.sum(result[0:i,j])) - np.log(i+1), \n",
    "                          np.log(i+1 - np.sum(result[0:i, j])) - np.log(i+1)])\n",
    "            p = np.exp(p - max(p))\n",
    "\n",
    "            if(np.random.uniform() < p[0]/np.sum(p)):\n",
    "                result[i, j] = 1\n",
    "            else:\n",
    "                result[i, j] = 0\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        x = K_plus + 1\n",
    "        y = K_plus + t\n",
    "        result[i, (x-1):y] = np.ones(t) #changed form np.ones([1, t])\n",
    "        K_plus = K_plus+t\n",
    "    result = result[:, 0:K_plus]\n",
    "    \n",
    "    return list([result, K_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "np.random.seed(1234)\n",
    "\n",
    "#Each image in our simulated data set is the superposition of four base images#\n",
    "# Number of images/ data points\n",
    "num_objects=100\n",
    "\n",
    "#Dimension of image (6x6)\n",
    "object_dim  = 6*6\n",
    "\n",
    "#Covariance matrix for images/ white noise\n",
    "sigma_x_orig = 0.5\n",
    "I = sigma_x_orig * np.identity(object_dim)\n",
    "\n",
    "#z_i - binary feature matrix (1 x 4) - each entry set to 1 with probability 0.5 and 0 otherwise#\n",
    "#x is data variable - each row correspondes to a superimposed built from a random combination of latent features#\n",
    "#with white noise added - x is built with multivariate gaussian#\n",
    "image_data = np.zeros((100,36))\n",
    "z_org = np.zeros((100,4))\n",
    "\n",
    "for i in range(0,num_objects):\n",
    "    z_org[i,:] = np.array([bernoulli.rvs(p=0.5, size=4)])\n",
    "    image_data[i,:] = np.dot(z_org[i,:],W) + np.random.normal(0,1, (1,object_dim)).dot(I) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Original Helper Functions'''\n",
    "\n",
    "# This function return the log likelihood\n",
    "def likelihood(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    part1 = (-1)*num_objects*(0.5*object_dim)*np.log(2*np.pi)\n",
    "    part2 = (-1)*(num_objects-K_plus)* object_dim *np.log(sigma_X) \n",
    "    part3 = (-1)*object_dim*K_plus*np.log(sigma_A) \n",
    "    part4 = (-1)*(0.5*object_dim)* np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) \n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T,(np.identity(num_objects) - np.dot(np.dot(Z,M),Z.T))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "    return(total)\n",
    "\n",
    "#This function computes matrix M\n",
    "def Mcalc(Z, sigma_X, sigma_A, K_plus):\n",
    "    M = np.linalg.inv(np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "    return(M)\n",
    "\n",
    "#This function samples new value of Z[i,k] using Gibbs Sampling\n",
    "def Met_zval(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim, i, k):    \n",
    "    \n",
    "    P=np.zeros(2)\n",
    "\n",
    "    Z[i,k]=1\n",
    "    #Compute posterior density of new_sample\n",
    "    M = Mcalc(Z, sigma_X, sigma_A, K_plus)\n",
    "    P[0] = likelihood(data, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(np.sum(Z[:, k]) - Z[i,k]) - np.log(num_objects)\n",
    "\n",
    "    #Set new_sample to 0\n",
    "    Z[i,k]=0\n",
    "    #Computer posterior density of new_sample\n",
    "    M = Mcalc(Z, sigma_X, sigma_A, K_plus)\n",
    "    P[1] = likelihood(data, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - np.sum(Z[:,k])) - np.log(num_objects)\n",
    "\n",
    "    P = np.exp(P - np.max(P))\n",
    "\n",
    "    if np.random.uniform(0,1) < (P[0]/(np.sum(P))):\n",
    "        new_sample = 1\n",
    "    else:\n",
    "        new_sample = 0\n",
    "    \n",
    "    return(new_sample)\n",
    "\n",
    "\n",
    "#This function samples new dishes upto a range specified by trunc_val\n",
    "def New_dishes(data, Z, sigma_X, sigma_A, K_plus, alpha, num_objects, object_dim, trunc_val,i):\n",
    "    trunc = np.zeros(trunc_val)\n",
    "    alpha_N = alpha/num_objects\n",
    "\n",
    "    for k_i in range(0,trunc_val):\n",
    "        Z_temp = Z\n",
    "        if k_i>0:\n",
    "            newcol = np.zeros((num_objects, k_i))\n",
    "            newcol[i,:] = 1 \n",
    "            Z_temp = np.column_stack((Z_temp, newcol))\n",
    "        M = Mcalc(Z_temp, sigma_X, sigma_A, K_plus+k_i)\n",
    "        trunc[k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood(data, Z_temp, M, sigma_A, sigma_X, K_plus+k_i, num_objects, object_dim)\n",
    "\n",
    "    trunc = np.exp(trunc - np.max(trunc))\n",
    "    trunc = trunc/np.sum(trunc)\n",
    "\n",
    "    p = np.random.uniform(0,1)\n",
    "    t = 0\n",
    "    new_dishes = 0\n",
    "\n",
    "    for k_i in range(0,trunc_val):\n",
    "        t = t + trunc[k_i]\n",
    "        if p < t:\n",
    "            new_dishes = k_i\n",
    "            break\n",
    "            \n",
    "    return(new_dishes)\n",
    "\n",
    "#The function updates both sigma_X and sigma_A using random-walk Metropolis-Hastings.\n",
    "def Met_sigma(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim):\n",
    "    \n",
    "    M = Mcalc(Z, sigma_X, sigma_A, K_plus)  \n",
    "    lik_curr = likelihood(data, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim)\n",
    "\n",
    "    if np.random.uniform(0,1) < 0.5:\n",
    "        sigma_X_new = sigma_X - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigma_X_new = sigma_X + np.random.uniform(0,1)/20\n",
    "\n",
    "    M = Mcalc(Z, sigma_X_new, sigma_A, K_plus)\n",
    "    lik_new_X = likelihood(data, Z, M, sigma_A, sigma_X_new, K_plus, num_objects, object_dim)\n",
    "\n",
    "    acc_X = np.exp(min(0, lik_new_X - lik_curr))\n",
    "\n",
    "    if np.random.uniform(0,1) < 0.5:\n",
    "        sigma_A_new = sigma_A - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigma_A_new = sigma_A + np.random.uniform(0,1)/20\n",
    "\n",
    "    M = Mcalc(Z, sigma_X, sigma_A_new, K_plus)\n",
    "    lik_new_A = likelihood(data, Z, M, sigma_A_new, sigma_X, K_plus, num_objects, object_dim)\n",
    "\n",
    "    acc_A = np.exp(min(0, lik_new_A - lik_curr))\n",
    "    \n",
    "    sigma_X_val=0\n",
    "    sigma_A_val=0\n",
    "\n",
    "    if np.random.uniform(0,1) < acc_X:\n",
    "        sigma_X_val = sigma_X_new\n",
    "    else:\n",
    "        sigma_X_val = sigma_X\n",
    "    \n",
    "    if np.random.uniform(0,1) < acc_A:\n",
    "        sigma_A_val = sigma_A_new\n",
    "    else:\n",
    "        sigma_A_val = sigma_A\n",
    "        \n",
    "    return list([sigma_X_val, sigma_A_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Original MCMC Sampler'''\n",
    "\n",
    "def Sampler(data, num_objects, object_dim, E=1000,  K_inf = 20, sigma_X = 1, sigma_A = 1, alpha = 1, trunc_val=5):\n",
    "    #Set storage arrays for sampled parameters\n",
    "    chain_Z = np.zeros([E, num_objects, K_inf])\n",
    "    chain_K = np.zeros([E, 1])\n",
    "    chain_sigma_X = np.zeros([E, 1])\n",
    "    chain_sigma_A = np.zeros([E, 1])\n",
    "    chain_alpha = np.zeros([E, 1])\n",
    "\n",
    "    #Initialize parameter values\n",
    "    num_object= np.shape(data)[0]\n",
    "    object_dim = np.shape(data)[1]\n",
    "    K_plus = 0\n",
    "    while K_plus == 0:\n",
    "        [Z, K_plus] = sampleIBP(alpha, num_objects)\n",
    "\n",
    "    #Compute Harmonic Number\n",
    "    HN = 0\n",
    "    for i in range(0, num_objects):\n",
    "        HN = HN + 1.0/(i+1)\n",
    "\n",
    "    for e in range(0, E):\n",
    "        #Store sampled values\n",
    "        chain_Z[e, :, 0:K_plus] = Z[:, 0:K_plus]\n",
    "        chain_K[e] = K_plus\n",
    "        chain_sigma_X[e] = sigma_X\n",
    "        chain_sigma_A[e] = sigma_A\n",
    "        chain_alpha[e] = alpha\n",
    "\n",
    "        if (e%100==0):\n",
    "            print(e)\n",
    "        #print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha) \n",
    "\n",
    "        #Generate a new value for Z[i,k] and accept by Metropolis\n",
    "        for i in range(0, num_objects):\n",
    "            #First we remove singular features if any\n",
    "            for k in range(0, K_plus):\n",
    "                if (k>=K_plus):\n",
    "                    break\n",
    "                if(Z[i, k] > 0):\n",
    "                    if (np.sum(Z[:, k]) - Z[i, k]) <= 0: \n",
    "                        Z[i, k] = 0\n",
    "                        Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                        K_plus = K_plus - 1\n",
    "                        Z = Z[:, 0:K_plus]\n",
    "                        continue\n",
    "                #Sample new values fo z_ik\n",
    "                Z[i,k] = Met_zval(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim, i, k)\n",
    "\n",
    "            #Sample new dishes \n",
    "            new_dishes = New_dishes(data, Z, sigma_X, sigma_A, K_plus, alpha, num_objects, object_dim, trunc_val,i)\n",
    "\n",
    "            if(new_dishes > 0):\n",
    "                newcol = np.zeros((num_objects, new_dishes))\n",
    "                newcol[i,:] = 1\n",
    "                Z = np.column_stack((Z, newcol))\n",
    "            K_plus = K_plus + new_dishes\n",
    "\n",
    "        #Sample sigma_X and sigma_A through Metropolis\n",
    "        [sigma_X, sigma_A] = Met_sigma(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim)\n",
    "        \n",
    "        #Sample alpha via Gibbs\n",
    "        alpha = np.random.gamma(1 + K_plus, 1/(1+HN))\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    return list([chain_Z, chain_K, chain_sigma_X, chain_sigma_A, chain_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import cython\n",
    "from libc.math cimport log\n",
    "\n",
    "cdef double pi = 3.141592653589793\n",
    "\n",
    "cdef sampleIBP_c(double alpha, long num_objects):  \n",
    "    cdef long i, j\n",
    "    cdef long t\n",
    "    cdef long x\n",
    "    cdef long y\n",
    "    cdef long K_plus\n",
    "\n",
    "    # Initializing storage for results\n",
    "    result = np.zeros([num_objects, 1000])\n",
    "\n",
    "    # Draw from the prior for alpha\n",
    "    t = np.random.poisson(alpha)\n",
    "    # Filling in first row of result matrix\n",
    "    result[0, 0:t] = np.ones(t) #changed form np.ones([1, t])\n",
    "    # Initializing K+\n",
    "    K_plus = t\n",
    "    \n",
    "    for i in range(1, num_objects):\n",
    "        for j in range(0, K_plus):\n",
    "            p = np.array([log(np.sum(result[0:i,j])) - log(i+1), \n",
    "                          log(i+1 - np.sum(result[0:i, j])) - log(i+1)])\n",
    "            p = np.exp(p - max(p))\n",
    "\n",
    "            if(np.random.uniform() < p[0]/np.sum(p)):\n",
    "                result[i, j] = 1\n",
    "            else:\n",
    "                result[i, j] = 0\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        x = K_plus + 1\n",
    "        y = K_plus + t\n",
    "        result[i, (x-1):y] = np.ones(t) #changed form np.ones([1, t])\n",
    "        K_plus = K_plus+t\n",
    "    result = result[:, 0:K_plus]\n",
    "\n",
    "    return list([result, K_plus])\n",
    "\n",
    "cdef double likelihood_opt_c(double[:,:] X, double[:, :] Z, double sigma_A, double sigma_X, \n",
    "                     long K_plus, long num_objects, long object_dim):\n",
    "\n",
    "    #Calculate M\n",
    "    cdef double[:, :] M = np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)\n",
    "    cdef double part1, part2, part3, part4, part5, total\n",
    "\n",
    "    part1 = (-1)*num_objects*(0.5*object_dim)*log(2*pi)\n",
    "    part2 = (-1)*(num_objects-K_plus)* object_dim *log(sigma_X) \n",
    "    part3 = (-1)*object_dim*K_plus*log(sigma_A) \n",
    "    part4 = (-1)*(0.5*object_dim)* log(np.linalg.det(M)) \n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T,(np.identity(num_objects) - np.dot(np.dot(Z,np.linalg.inv(M)),Z.T))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "\n",
    "    return(total)\n",
    "\n",
    "#This function samples new value of Z[i,k] and accepts by Metropolis\n",
    "cdef int Met_zval_c(double[:, :] data, double[:,:] Z, double sigma_X, double sigma_A, int K_plus, long num_objects, long object_dim, long i, long k):    \n",
    "    \n",
    "    cdef double[:]  P\n",
    "    cdef int new_sample\n",
    "    \n",
    "    P=np.zeros(2)\n",
    "\n",
    "    Z[i,k]=1\n",
    "    #Compute posterior density of new_sample\n",
    "    P[0] = likelihood_opt_c(data, Z, sigma_A, sigma_X, K_plus, num_objects, object_dim) + log(np.sum(Z[:, k]) - Z[i,k]) - log(num_objects)\n",
    "\n",
    "    #Set new_sample to 0\n",
    "    Z[i,k]=0\n",
    "    #Computer posterior density of new_sample\n",
    "    P[1] = likelihood_opt_c(data, Z, sigma_A, sigma_X, K_plus, num_objects, object_dim) + log(num_objects - np.sum(Z[:,k])) - log(num_objects)\n",
    "\n",
    "    P = np.exp(P - np.max(P))\n",
    "\n",
    "    if np.random.uniform(0,1) < (P[0]/(np.sum(P))):\n",
    "        new_sample = 1\n",
    "    else:\n",
    "        new_sample = 0\n",
    "    \n",
    "    return(new_sample)\n",
    "\n",
    "\n",
    "cdef int New_dishes_c(double[:,:] data, double[:,:] Z, double sigma_X, double  sigma_A, int K_plus, double alpha, long num_objects, long object_dim, long trunc_val, long i):\n",
    "    \n",
    "    trunc = np.zeros(trunc_val)\n",
    "    cdef double alpha_N = alpha/num_objects\n",
    "    cdef int k_i, new_dishes\n",
    "    cdef double[:,:] Z_temp, newcol\n",
    "    cdef double p, t\n",
    "    \n",
    "\n",
    "    for k_i in range(0,trunc_val):\n",
    "        Z_temp = Z\n",
    "        if k_i>0:\n",
    "            newcol = np.zeros((num_objects, k_i))\n",
    "            newcol[i,:] = 1 \n",
    "            Z_temp = np.column_stack((Z_temp, newcol))\n",
    "        trunc[k_i] = k_i * log(alpha_N) - alpha_N - log(np.math.factorial(k_i)) + likelihood_opt_c(data, Z_temp, sigma_A, sigma_X, K_plus+k_i, num_objects, object_dim)\n",
    "\n",
    "    trunc = np.exp(trunc - np.max(trunc))\n",
    "    trunc = trunc/np.sum(trunc)\n",
    "\n",
    "    p = np.random.uniform(0,1)\n",
    "    t = 0\n",
    "    new_dishes = 0\n",
    "\n",
    "    for k_i in range(0,trunc_val):\n",
    "        t = t + trunc[k_i]\n",
    "        if p < t:\n",
    "            new_dishes = k_i\n",
    "            break\n",
    "            \n",
    "    return(new_dishes)\n",
    "\n",
    "\n",
    "cdef Met_sigma_c(double[:,:] data, double[:,:] Z, double sigma_X, double sigma_A, int K_plus, long num_objects, long object_dim):\n",
    "    \n",
    "    cdef double sigma_X_new, sigma_A_new, lik_new_X, lik_new_A, acc_X, acc_A, sigma_X_val, sigma_A_val \n",
    "    \n",
    "    cdef double lik_curr = likelihood_opt_c(data, Z, sigma_A, sigma_X, K_plus, num_objects, object_dim)\n",
    "\n",
    "    if np.random.uniform(0,1) < 0.5:\n",
    "        sigma_X_new = sigma_X - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigma_X_new = sigma_X + np.random.uniform(0,1)/20\n",
    "\n",
    "    lik_new_X = likelihood_opt_c(data, Z, sigma_A, sigma_X_new, K_plus, num_objects, object_dim)\n",
    "\n",
    "    acc_X = np.exp(min(0, lik_new_X - lik_curr))\n",
    "\n",
    "    if np.random.uniform(0,1) < 0.5:\n",
    "        sigma_A_new = sigma_A - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigma_A_new = sigma_A + np.random.uniform(0,1)/20\n",
    "\n",
    "    lik_new_A = likelihood_opt_c(data, Z, sigma_A_new, sigma_X, K_plus, num_objects, object_dim)\n",
    "\n",
    "    acc_A = np.exp(min(0, lik_new_A - lik_curr))\n",
    "    \n",
    "    sigma_X_val=0\n",
    "    sigma_A_val=0\n",
    "\n",
    "    if np.random.uniform(0,1) < acc_X:\n",
    "        sigma_X_val = sigma_X_new\n",
    "    else:\n",
    "        sigma_X_val = sigma_X\n",
    "    \n",
    "    if np.random.uniform(0,1) < acc_A:\n",
    "        sigma_A_val = sigma_A_new\n",
    "    else:\n",
    "        sigma_A_val = sigma_A\n",
    "        \n",
    "    return list([sigma_X_val, sigma_A_val])\n",
    "\n",
    "\n",
    "\n",
    "def sampler_opt_c(double[:,:] data, long E=1000, long K_inf = 20, double sigma_X = 1, double sigma_A = 1, double alpha = 1, int trunc_val=5):\n",
    "    \n",
    "    cdef long num_objects= np.shape(data)[0]\n",
    "    cdef long object_dim = np.shape(data)[1]\n",
    "    \n",
    "    #Set storage arrays for sampled parameters\n",
    "    cdef double[:, :, :] chain_Z = np.zeros([E, num_objects, K_inf])\n",
    "    cdef double[:, :] chain_K = np.zeros([E, 1])\n",
    "    cdef double[:, :] chain_sigma_X = np.zeros([E, 1])\n",
    "    cdef double[:, :] chain_sigma_A = np.zeros([E, 1])\n",
    "    cdef double[:, :] chain_alpha = np.zeros([E, 1])\n",
    "    \n",
    "    cdef double HN\n",
    "    cdef long i, e, j1, j2, k, k_i, TEMP\n",
    "\n",
    "    #Initialize parameter values\n",
    "    \n",
    "    K_plus = 0\n",
    "    while K_plus == 0:\n",
    "        [Z, K_plus] = sampleIBP_c(alpha, num_objects)\n",
    "\n",
    "    #Compute Harmonic Number\n",
    "    HN = 0\n",
    "    for i in range(0, num_objects):\n",
    "        HN = HN + 1.0/(i+1)\n",
    "\n",
    "    for e in range(0, E):\n",
    "        #Store sampled values\n",
    "        for j1 in range(num_objects):\n",
    "            for j2 in range(K_plus):\n",
    "                chain_Z[e, j1, j2] = Z[j1, j2]\n",
    "        chain_K[e] = K_plus\n",
    "        chain_sigma_X[e] = sigma_X\n",
    "        chain_sigma_A[e] = sigma_A\n",
    "        chain_alpha[e] = alpha\n",
    "\n",
    "        #if (e%100==0):\n",
    "        #    print(e)\n",
    "        #print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha) \n",
    "\n",
    "        #Generate a new value for Z[i,k] and accept by Metropolis\n",
    "        for i in range(0, num_objects):\n",
    "            #First we remove singular features if any\n",
    "            for k in range(0, K_plus):\n",
    "                if (k>=K_plus):\n",
    "                    break\n",
    "                if(Z[i, k] > 0):\n",
    "                    if (np.sum(Z[:, k]) - Z[i, k]) <= 0: \n",
    "                        Z[i, k] = 0\n",
    "                        Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                        K_plus = K_plus - 1\n",
    "                        Z = Z[:, 0:K_plus]\n",
    "                        continue\n",
    "                #Compute conditional distribution for current cell\n",
    "                TEMP = Met_zval_c(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim, i, k)\n",
    "                Z[i,k] = TEMP\n",
    "\n",
    "\n",
    "            #Sample new dishes by Metropolis\n",
    "            new_dishes = New_dishes_c(data, Z, sigma_X, sigma_A, K_plus, alpha, num_objects, object_dim, trunc_val,i)\n",
    "\n",
    "            if(new_dishes > 0):\n",
    "                newcol = np.zeros((num_objects, new_dishes))\n",
    "                newcol[i,:] = 1\n",
    "                Z = np.column_stack((Z, newcol))\n",
    "            K_plus = K_plus + new_dishes\n",
    "\n",
    "        #Sample sigma_X and sigma_A through Metropolis\n",
    "        [sigma_X, sigma_A] = Met_sigma_c(data, Z, sigma_X, sigma_A, K_plus, num_objects, object_dim)\n",
    "        #Sample alpha via Gibbs\n",
    "        alpha = np.random.gamma(1 + K_plus, 1/(1+HN))\n",
    "    \n",
    "    print(\"Complete\")\n",
    "    return list([chain_Z, chain_K, chain_sigma_X, chain_sigma_A, chain_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Complete\n",
      "0\n",
      "Complete\n",
      "0\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Sampler</th>\n",
       "      <td>58.640440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cythonized Optimized Sampler</th>\n",
       "      <td>48.795563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Time\n",
       "Original Sampler              58.640440\n",
       "Cythonized Optimized Sampler  48.795563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Setting values to use in likelihood function comparisons\n",
    "num_objects = image_data.shape[0]\n",
    "object_dim = image_data.shape[1]\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "Z, K_plus = sampleIBP(alpha,num_objects)\n",
    "\n",
    "# Time the original likelihood function\n",
    "loops = 3\n",
    "time_sampler=np.zeros(loops)\n",
    "for l in range(loops):\n",
    "    t0=time.time()\n",
    "    Sampler(image_data, num_objects, object_dim, E=100,  K_inf = 20, sigma_X = 1, sigma_A = 1, alpha = 1, trunc_val=5)\n",
    "    t1=time.time()\n",
    "    time_sampler[l]=t1-t0\n",
    "mean_time_sampler = round(np.mean(time_sampler),7)\n",
    "\n",
    "np.random.seed(1234)\n",
    "# Time the optimized likelihood function\n",
    "time_sampler_opt_c = np.zeros(loops)\n",
    "for l in range(loops):\n",
    "    t0 = time.time()\n",
    "    sampler_opt_c(image_data, E=100, K_inf = 20, sigma_X = 1, sigma_A = 1, alpha = 1, trunc_val=5)\n",
    "    t1 = time.time()\n",
    "    time_sampler_opt_c[l] = t1-t0\n",
    "mean_time_sampler_opt_c = round(np.mean(time_sampler_opt_c), 7)\n",
    "\n",
    "time_array = np.array([mean_time_sampler, mean_time_sampler_opt_c])\n",
    "\n",
    "cols = [\"Time\"]\n",
    "index = [\"Original Sampler\", \"Cythonized Optimized Sampler\"]\n",
    "\n",
    "time_df = pd.DataFrame(time_array, columns = cols, index = index)\n",
    "time_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
